{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Expected Gradients and the Differences method\n"
      ],
      "metadata": {
        "id": "yJir3B7H0KP3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.models import resnet18\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm.notebook import tqdm_notebook\n",
        "from io import StringIO # creates an in-memory text stream that you can read from or write to, just like a file\n",
        "from scipy import ndimage # performs image processing tasks such as filtering, interpolation, and measurements on images\n",
        "from textwrap import wrap\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL.Image # performs image-related tasks like loading an image file, converting between different image formats\n",
        "import io # works with streams like files, buffers, and other I/O operations\n",
        "torch.manual_seed(42)\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "adv_model = resnet18()\n",
        "adv_model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "adv_model.maxpool = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
        "adv_model.fc = nn.Linear(512, 10)\n",
        "\n",
        "\n",
        "adv_model.load_state_dict(torch.load(\"/content/drive/MyDrive/adv_cifar10_model.pth\")[\"model_state_dict\"])\n",
        "adv_pruned_model = torch.load('/content/drive/MyDrive/adv_cifar10_model_pruned.pth')['model']\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "adv_model.to(device)\n",
        "adv_pruned_model.to(device)\n",
        "\n",
        "# Switching to evaluation mode\n",
        "adv_model.eval()\n",
        "adv_pruned_model.eval()\n"
      ],
      "metadata": {
        "id": "02qytT7VtEBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualization\n"
      ],
      "metadata": {
        "id": "GV8L5lyqzzWP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing expected gradients\n",
        "def ConvertToGrayscale(attributions):\n",
        "    return np.average(attributions, axis = 2)\n",
        "\n",
        "def Polarity(attributions, polarity):\n",
        "    if polarity == 'positive':\n",
        "        return np.clip(attributions, 0, 1)\n",
        "    elif polarity == 'negative':\n",
        "        return np.clip(attributions, -1, 0)\n",
        "    else:\n",
        "        raise ValueError('Wrong value for polarity')\n",
        "\n",
        "def ComputeThresholdByTopPercentage(attributions, percentage = 60, plot_distribution = True):\n",
        "    if percentage < 0 or percentage > 100:\n",
        "        raise ValueError('Percentage must be in range [0, 100]')\n",
        "\n",
        "    if percentage == 100:\n",
        "        return np.min(attributions)\n",
        "\n",
        "    flat_attributions = attributions.flatten()\n",
        "    sum_attributions = np.sum(flat_attributions)\n",
        "\n",
        "    sorted_attributions = np.sort(np.abs(flat_attributions))[::-1]\n",
        "\n",
        "    cum_sum = 100.0 * np.cumsum(sorted_attributions) / sum_attributions\n",
        "\n",
        "    threshold_idx = np.where(cum_sum >= percentage)[0][0]\n",
        "    threshold = sorted_attributions[threshold_idx]\n",
        "\n",
        "    if plot_distribution:\n",
        "        values_to_plot = np.where(cum_sum >= 95)[0][0]\n",
        "        values_to_plot = max(values_to_plot, threshold_idx)\n",
        "        plt.plot(np.arange(values_to_plot), sorted_attributions[:values_to_plot])\n",
        "        plt.axvline(x = threshold_idx)\n",
        "        plt.show()\n",
        "\n",
        "    return threshold\n",
        "\n",
        "def LinearTransform(attributions, clip_above_percentile = 99.9, clip_below_percentile = 70.0, low = 0.2, plot_distribution = False):\n",
        "    if clip_above_percentile < 0 or clip_above_percentile > 100:\n",
        "        raise ValueError('clip_above_percentile must be in range [0, 100]')\n",
        "\n",
        "    if clip_below_percentile < 0 or clip_below_percentile > 100:\n",
        "        raise ValueError('clip_below_percentile must be in range [0, 100]')\n",
        "\n",
        "    if low > 1 or low < 0:\n",
        "        raise ValueError('low must be in range [0, 1]')\n",
        "\n",
        "    m = ComputeThresholdByTopPercentage(attributions, percentage = 100 - clip_above_percentile, plot_distribution = plot_distribution)\n",
        "    e = ComputeThresholdByTopPercentage(attributions, percentage = 100 - clip_below_percentile, plot_distribution = plot_distribution)\n",
        "\n",
        "    transformed = (1 - low) * (np.abs(attributions) - e) / (m - e) + low\n",
        "\n",
        "    transformed *= np.sign(attributions)\n",
        "\n",
        "    transformed *= (transformed >= low)\n",
        "\n",
        "    transformed = np.clip(transformed, 0.0, 1.0)\n",
        "    return transformed\n",
        "\n",
        "def Binarize(attributions, threshold = 0.001):\n",
        "    return attributions > threshold\n",
        "\n",
        "def MorphologicalCleanUp(attributions, structure = np.ones((4, 4))):\n",
        "    closed = ndimage.grey_closing(attributions, structure = structure)\n",
        "    opened = ndimage.grey_opening(closed, structure = structure)\n",
        "    return opened\n",
        "\n",
        "def Outlines(attributions, percentage = 90, connected_component_structure = np.ones((3, 3)), plot_distributions = True):\n",
        "    attributions = Binarize(attributions)\n",
        "    attributions = ndimage.binary_fill_holes(attributions)\n",
        "\n",
        "    connected_components, num_cc = ndimage.measurements.label(attributions, structure = connected_component_structure)\n",
        "    sum_connected_components = np.sum(attributions[connected_components > 0])\n",
        "\n",
        "    component_sums_and_structures = []\n",
        "\n",
        "    for cc_idx in range(1, 1 + num_cc):\n",
        "        cc_mask = connected_components == cc_idx\n",
        "        component_sum = np.sum(attributions[cc_mask])\n",
        "        component_sums_and_structures.append((component_sum, cc_mask))\n",
        "\n",
        "    sorted_sums_and_masks = sorted(component_sums_and_structures, lambda x: x[0], reverse = True)\n",
        "    sorted_sums = list(zip(*sorted_sums_and_masks))[0]\n",
        "    cumulative_sums = np.cumsum(sorted_sums)\n",
        "    cutoff_threshold = percentage * sum_connected_components / 100.0\n",
        "    cutoff_idx = np.where(cumulative_sums >= cutoff_threshold)[0][0]\n",
        "\n",
        "    if cutoff_idx > 2:\n",
        "        cutoff_idx = 2\n",
        "\n",
        "    borded_mask = np.zeros_like(attributions)\n",
        "    for i in range(1 + cutoff_idx):\n",
        "        borded_mask[sorted_sums_and_masks[i][1]] = 1\n",
        "\n",
        "    if plot_distributions:\n",
        "        plt.plot(np.arange(len(sorted_sums)), sorted_sums)\n",
        "        plt.axvline(x = cutoff_idx)\n",
        "        plt.show()\n",
        "\n",
        "    eroded_mask = ndimage.binary_erosion(borded_mask, iterations = 1)\n",
        "    borded_mask[eroded_mask] = 0\n",
        "\n",
        "    return borded_mask\n",
        "\n",
        "def Overlay(attributions, image):\n",
        "  # Create a new figure for the overlay\n",
        "    fig, ax = plt.subplots()\n",
        "    image = np.expand_dims(ConvertToGrayscale(image), 2) * [1, 1, 1]\n",
        "    plt.imshow(np.clip(0, 255, attributions).astype(np.uint8))\n",
        "    plt.imshow(np.clip(0, 255, image).astype(np.uint8), alpha = 0.15)\n",
        "    plt.tight_layout()\n",
        "    plt.axis('off')\n",
        "    buf = io.BytesIO()\n",
        "    a = plt.savefig(buf, bbox_inches = 'tight')\n",
        "    buf.seek(0)\n",
        "    plt.close(fig)\n",
        "    pil1 = PIL.Image.open(buf)\n",
        "    return pil1\n",
        "\n",
        "G = [0, 255, 38]\n",
        "R = [255, 0, 0]\n",
        "\n",
        "def Visualize(attributions, image, positive_channel=G, negative_channel=R, polarity='positive', clip_above_percentile=99.9, clip_below_percentile=0, morphological_cleanup=False, structure=np.ones((3, 3)), outlines=False, outlines_component_percentage=90, overlay=True, plot_distribution=False):\n",
        "    if polarity == 'both':\n",
        "        pos_attributions = Visualize(\n",
        "            attributions, image, positive_channel=positive_channel,\n",
        "            negative_channel=negative_channel, polarity='positive',\n",
        "            clip_above_percentile=clip_above_percentile, clip_below_percentile=clip_below_percentile,\n",
        "            morphological_cleanup=morphological_cleanup, outlines=outlines,\n",
        "            outlines_component_percentage=outlines_component_percentage,\n",
        "            overlay=False,\n",
        "            plot_distribution=plot_distribution)\n",
        "\n",
        "        neg_attributions = Visualize(\n",
        "            attributions, image, positive_channel=positive_channel,\n",
        "            negative_channel=negative_channel, polarity='negative',\n",
        "            clip_above_percentile=clip_above_percentile, clip_below_percentile=clip_below_percentile,\n",
        "            morphological_cleanup=morphological_cleanup, outlines=outlines,\n",
        "            outlines_component_percentage=outlines_component_percentage,\n",
        "            overlay=False,\n",
        "            plot_distribution=plot_distribution)\n",
        "\n",
        "        attributions = pos_attributions + neg_attributions\n",
        "\n",
        "        if overlay:\n",
        "            attributions = Overlay(attributions, image)\n",
        "\n",
        "        return attributions\n",
        "\n",
        "    elif polarity == 'positive':\n",
        "        attributions = Polarity(attributions, polarity=polarity)\n",
        "        channel = positive_channel\n",
        "    elif polarity == 'negative':\n",
        "        attributions = Polarity(attributions, polarity=polarity)\n",
        "        attributions = np.abs(attributions)\n",
        "        channel = negative_channel\n",
        "\n",
        "    attributions = ConvertToGrayscale(attributions)\n",
        "\n",
        "    attributions = LinearTransform(attributions,\n",
        "                                   clip_above_percentile, clip_below_percentile,\n",
        "                                   0.0,\n",
        "                                   plot_distribution=plot_distribution)\n",
        "\n",
        "    if morphological_cleanup:\n",
        "        attributions = MorphologicalCleanUp(attributions, structure=structure)\n",
        "    if outlines:\n",
        "        attributions = Outlines(attributions,\n",
        "                                percentage=outlines_component_percentage,\n",
        "                                plot_distribution=plot_distribution)\n",
        "\n",
        "    attributions = np.expand_dims(attributions, 2) * channel\n",
        "\n",
        "    if overlay:\n",
        "        attributions = Overlay(attributions, image)\n",
        "\n",
        "    return attributions"
      ],
      "metadata": {
        "id": "UR2SUaTDs95z"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Expected Gradients"
      ],
      "metadata": {
        "id": "3_wZja44z3PI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Expected Gradients\n",
        "class ExpectedGradients:\n",
        "    def __init__(self, model, normalizer=lambda x: x):\n",
        "        self.model = model\n",
        "        self.device = torch.device(\n",
        "            'cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.normalizer = normalizer\n",
        "\n",
        "    def ToTensor(self, inp):\n",
        "        inp = np.array(inp)\n",
        "        inp = np.transpose(inp, (-1, 0, 1))\n",
        "        inp_tensor = torch.from_numpy(inp).float().unsqueeze(0).to(self.device)\n",
        "        return inp_tensor\n",
        "\n",
        "    def PredictionsGradients(self, inp, target_label_idx):\n",
        "        inp = inp.clone().requires_grad_(True)\n",
        "        outputs = self.model(inp)\n",
        "        outputs = F.softmax(outputs, dim = -1)[:, target_label_idx]\n",
        "        outputs.backward(torch.ones(outputs.shape).to(self.device))\n",
        "        gradients = inp.grad.detach().clone()\n",
        "        return gradients, outputs.detach().clone().cpu().numpy()\n",
        "\n",
        "    def GenerateSaturatedBatches(self, inp, baseline, steps):\n",
        "        alphas = torch.linspace(0.0, 1.0, steps+1).to(self.device)\n",
        "        alphas = alphas[:, None, None, None]\n",
        "        images = baseline + alphas * (inp - baseline)\n",
        "        return images\n",
        "\n",
        "    def ExpectedGrads(self, inp, target_label_idx, baseline, steps = 50, batch_size = 30):\n",
        "        scaled_inputs = self.GenerateSaturatedBatches(inp, baseline, steps)\n",
        "        gradients = []\n",
        "        predictions = []\n",
        "        for i in range(0, scaled_inputs.shape[0], batch_size):\n",
        "            start = i\n",
        "            end = min(start + batch_size, scaled_inputs.shape[0])\n",
        "            batch = scaled_inputs[start:end]\n",
        "            batch = self.normalizer(batch)\n",
        "            gradient, pred = self.PredictionsGradients(batch, target_label_idx)\n",
        "            predictions.append(pred)\n",
        "            gradients.append(gradient)\n",
        "        predictions = np.hstack(predictions)\n",
        "        gradients = torch.cat(gradients, axis = 0)\n",
        "        inp = self.normalizer(inp)\n",
        "        baseline = self.normalizer(baseline)\n",
        "        gradients = (gradients[:-1] + gradients[1:]) / 2.0\n",
        "        integrated_grads = torch.mean(gradients, axis = 0)\n",
        "        delta_X = (inp - baseline).to(self.device)\n",
        "        integrated_grads = (delta_X * integrated_grads).squeeze(0).detach().cpu().numpy()\n",
        "        integrated_grads = np.transpose(integrated_grads, (1, 2, 0))\n",
        "        completeness = np.abs(np.sum(integrated_grads) - (predictions[-1] - predictions[0]))\n",
        "        return integrated_grads, completeness, predictions\n",
        "\n",
        "    def Visualization(self, grad, image, treshold = 0):\n",
        "        return Visualize(grad, (image * 255).astype(np.uint8), clip_below_percentile = treshold)\n",
        "\n",
        "    def GaussianNoise(self, inp, target_label_idx, steps, num_random_trials, batch_size = 30, tqdm_p = True):\n",
        "        inp = self.ToTensor(inp)\n",
        "        all_intgrads = []\n",
        "        itr = range(num_random_trials)\n",
        "        if tqdm_p == True:\n",
        "            itr = tqdm(itr, unit=\"trial\")\n",
        "        completeness = []\n",
        "        preds = []\n",
        "        for i in itr:\n",
        "            integrated_grad, cm, predictions = self.ExpectedGrads(inp, target_label_idx, baseline=torch.normal(0, 0.4, inp.shape).to(self.device), steps = steps, batch_size = batch_size)\n",
        "            preds.append(predictions)\n",
        "            all_intgrads.append(integrated_grad)\n",
        "            completeness.append(cm)\n",
        "            if tqdm_p:\n",
        "                itr.set_postfix(completeness = np.average(completeness))\n",
        "        exp_grads = np.average(np.array(all_intgrads), axis = 0)\n",
        "        return exp_grads, preds\n",
        "\n",
        "    def RandomBaseline(self, inp, target_label_idx, steps, num_random_trials, batch_size = 30, tqdm_p = True):\n",
        "        inp = self.ToTensor(inp)\n",
        "        all_intgrads = []\n",
        "        itr = range(num_random_trials)\n",
        "        if tqdm_p == True:\n",
        "            itr = tqdm(itr, unit = \"trial\")\n",
        "        completeness = []\n",
        "        preds = []\n",
        "        for i in itr:\n",
        "            integrated_grad, cm, predictions = self.ExpectedGrads(inp, target_label_idx, baseline = torch.rand(inp.shape).to(self.device), steps = steps, batch_size = batch_size)\n",
        "            preds.append(predictions)\n",
        "            all_intgrads.append(integrated_grad)\n",
        "            completeness.append(cm)\n",
        "            if tqdm_p:\n",
        "                itr.set_postfix(completeness=np.average(completeness))\n",
        "        exp_grads = np.average(np.array(all_intgrads), axis = 0)\n",
        "        return exp_grads, preds"
      ],
      "metadata": {
        "id": "Hmol5bNZtM7M"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformations, loading dataset and getting a batch for visualization\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "normalizer = transforms.Normalize((0.49139968, 0.48215827 ,0.44653124), (0.24703233, 0.24348505, 0.26158768))\n",
        "test_set = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "test_loader = DataLoader(test_set, batch_size=200, shuffle=False)\n",
        "classes = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
        "\n",
        "images, labels =  next(iter(test_loader))"
      ],
      "metadata": {
        "id": "dih5_bCJ08da"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plots and the Differences Method"
      ],
      "metadata": {
        "id": "__eprdKNz6qp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def expected_gradients_compare(adv_model, adv_pruned_model, images, labels, classes, normalizer=lambda x: x):\n",
        "    adv_expected_grad = ExpectedGradients(adv_model, normalizer = normalizer)\n",
        "    adv_pruned_expected_grad = ExpectedGradients(adv_pruned_model, normalizer = normalizer)\n",
        "    number_of_img = labels.shape[0]\n",
        "    labels_text = ['\\n'.join(wrap(classes[l.item()], 20)) for l in labels.cpu()]\n",
        "    num_columns = np.ceil(number_of_img / 12).astype(int)\n",
        "    fig = plt.figure(figsize = (15.6 * num_columns, 48))\n",
        "    subfigs = fig.subfigures(nrows = 1, ncols = num_columns)\n",
        "    k = 0\n",
        "    for j, sub in enumerate(subfigs):\n",
        "        sub2 = sub.subfigures(nrows = 8, ncols = 1)\n",
        "        for i, subfig in enumerate(sub2):\n",
        "            if number_of_img == k:\n",
        "                break\n",
        "            axs = subfig.subplots(nrows=1, ncols=4)\n",
        "            if i == 0:\n",
        "                axs[0].set_title(\"Original image\", fontsize = 20)\n",
        "                axs[1].set_title(\"Robust\", fontsize = 20)\n",
        "                axs[2].set_title(\"Robust pruned\", fontsize = 20)\n",
        "                axs[3].set_title(\"Differences\", fontsize = 20)\n",
        "            img = images[k:k+1].to(device)\n",
        "            img = normalizer(img)\n",
        "            adv_prediction = adv_model(img)\n",
        "            adv_pruned_prediction = adv_pruned_model(img)\n",
        "            image = images[k].cpu().permute(1, 2, 0).numpy()\n",
        "            adv_grad, _ = adv_expected_grad.RandomBaseline(image, adv_prediction.argmax(dim=1).item(), steps=50, num_random_trials=100, batch_size=30)\n",
        "            adv_pruned_grad, _ = adv_pruned_expected_grad.RandomBaseline(image, adv_pruned_prediction.argmax(dim=1).item(), steps=50, num_random_trials=100, batch_size=30)\n",
        "\n",
        "            adv_pred = '\\n'.join(wrap(classes[adv_prediction.argmax(dim=1).item()], 12))\n",
        "            adv_pruned_pred = '\\n'.join(wrap(classes[adv_pruned_prediction.argmax(dim=1).item()], 12))\n",
        "\n",
        "            axs[0].set_xlabel('\\n'.join(wrap(labels_text[k], 10)), fontsize=35)\n",
        "            axs[0].imshow(image)\n",
        "\n",
        "            axs[1].set_xlabel(f\"{adv_pred}\", fontsize=35)\n",
        "            axs[1].imshow(adv_expected_grad.Visualization(adv_grad, image))\n",
        "\n",
        "            axs[2].set_xlabel(f\"{adv_pruned_pred}\", fontsize=35)\n",
        "            axs[2].imshow(adv_pruned_expected_grad.Visualization(adv_pruned_grad, image))\n",
        "\n",
        "            # The Differences Method\n",
        "            adv_grad = np.average(adv_grad, axis = 2)\n",
        "            adv_pruned_grad = np.average(adv_pruned_grad, axis = 2)\n",
        "\n",
        "            sum_adv_gradients = np.sum(adv_grad)\n",
        "            sum_adv_pruned_gradients = np.sum(adv_pruned_grad)\n",
        "\n",
        "\n",
        "            if(sum_adv_gradients > sum_adv_pruned_gradients):\n",
        "                scalling_difference = sum_adv_gradients - sum_adv_pruned_gradients\n",
        "                value_per_pixel = scalling_difference / 1024 # 32 pixels by 32 pixels\n",
        "\n",
        "                for i in range(32):\n",
        "                    for j in range(32):\n",
        "                        adv_pruned_grad[i][j] += value_per_pixel\n",
        "\n",
        "\n",
        "\n",
        "            if(sum_adv_pruned_gradients > sum_adv_gradients):\n",
        "                scalling_difference = sum_adv_pruned_gradients - sum_adv_gradients\n",
        "                value_per_pixel = scalling_difference / 1024 # 32 pixels by 32 pixels\n",
        "\n",
        "                for i in range(32):\n",
        "                    for j in range(32):\n",
        "                        adv_grad[i][j] += value_per_pixel\n",
        "\n",
        "\n",
        "\n",
        "            difference_image = torch.zeros(32, 32, 3, dtype=torch.uint8)\n",
        "            for i in range(32):\n",
        "                for j in range(32):\n",
        "                    if((adv_pruned_grad[i][j] - adv_grad[i][j]) > 0):\n",
        "                        difference_image[i][j] = torch.tensor([0, 255, 38], dtype=torch.uint8)\n",
        "                    if((adv_pruned_grad[i][j] - adv_grad[i][j]) < 0):\n",
        "                        difference_image[i][j] = torch.tensor([255, 0, 0], dtype=torch.uint8)\n",
        "            difference_image_np = difference_image.numpy()\n",
        "\n",
        "\n",
        "            axs[3].imshow(difference_image_np)\n",
        "\n",
        "            for t in range(4):\n",
        "                axs[t].set_xticklabels([])\n",
        "                axs[t].set_yticklabels([])\n",
        "                axs[t].spines['top'].set_visible(False)\n",
        "                axs[t].spines['right'].set_visible(False)\n",
        "                axs[t].spines['left'].set_visible(False)\n",
        "                axs[t].spines['bottom'].set_visible(False)\n",
        "            k += 1"
      ],
      "metadata": {
        "id": "zYVE_hnf1mDS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}